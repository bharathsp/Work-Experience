# Publicis Sapient

<img width="150" height="90" alt="image" src="https://github.com/user-attachments/assets/8f3fd166-c04a-48d2-9245-211365c60176" />

ðŸ“… **Date:** 30 July 2025 - 21 Oct 2025

ðŸ‘¤ **Role:** Senior Associate Data Engineering L1

## Projects:

### **Tesco**

#### ðŸ“… **Date:** Aug 2025 - Oct 2025

#### **â—‰ Project Overview**
Worked as part of the Data Engineering team at Tesco, responsible for designing, maintaining, and optimizing on-premise data pipelines that supported large-scale analytical workloads and business reporting.

#### **â—‰ Tools Used** 
HBase, HDFS, PySpark, Hive, Sqoop, Xcoms, Cloudera clusters

#### **â—‰ Responsibilities**
* Developed and maintained ETL pipelines to ingest, transform, and store large volumes of structured and unstructured data from multiple business sources.
* Ensured data reliability, scalability, and performance across Cloudera-managed Hadoop clusters.
* Collaborated with cross-functional teams to optimize data workflows for analytics, reporting, and downstream data science use cases.

#### **â—‰ Key Achievements**
* Improved pipeline efficiency by 35% through PySpark code optimization and better partitioning strategies in Hive tables.
* Reduced data ingestion time by 40% by parallelizing Sqoop imports and tuning cluster resource allocation on Cloudera.
* Successfully migrated 20+ TB of legacy data to a new data model in Hive with zero data loss and minimal downtime.
* Enhanced real-time reporting performance by optimizing HBase read/write configurations.


#### **â—‰ Challenges**
* Performance bottlenecks during large-scale data transformations. Rewrote inefficient PySpark jobs, leveraged broadcast joins, and introduced data partitioning and caching strategies.
* Data inconsistency across multiple ingestion sources. Implemented automated validation and reconciliation scripts with Airflow XComs to cross-check record counts and schema alignment.
* High latency in Hive queries used for business dashboards. Optimized Hive table design with ORC format, bucketing, and dynamic partition pruning.
